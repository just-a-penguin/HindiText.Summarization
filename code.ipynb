{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('2022_data/train.csv')      #2022\n",
    "# df_test = pd.read_csv('hindi_train.csv')  #2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Article</th>\n",
       "      <th>Heading</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a3d72cd62e7e1b5529dd254a85fa2b5a</td>\n",
       "      <td>भुवनेश्वर : भारत ने शनिवार को ओडिशा के बालासोर...</td>\n",
       "      <td>भारत की बढ़ी ताकत, ‘अग्नि प्राइम’ मिसाइल का हु...</td>\n",
       "      <td>भारत ने शनिवार को ओडिशा के बालासोर तट पर ‘अग्न...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f8904fd63c1d257dc5ee9b529df4a097</td>\n",
       "      <td>नई दिल्ली। देश में कोरोना की संभावित तीसरी लहर...</td>\n",
       "      <td>Covid-19 Vaccination: देश में कोविड टीके की 40...</td>\n",
       "      <td>केंद्रीय स्वास्थ्य मंत्रालय के मुताबिक, आज शाम...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e89ee2300613ae0c0e8db4ed0e2c7aa</td>\n",
       "      <td>बीजेपी यूपी में जनवरी के दूसरे हफ्ते से ब्राह्...</td>\n",
       "      <td>यूपी में ब्राह्मण वोटरों को साधने की तैयारी कर...</td>\n",
       "      <td>बीजेपी के केंद्र सरकार में ब्राह्मण मंत्रियों,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9a382557dc6afda0dfaf04210d16224f</td>\n",
       "      <td>बागपत: उत्तर प्रदेश के बागपत में बिना अनुमति क...</td>\n",
       "      <td>बागपत में बिना इजाजत दाढ़ी रखने पर दरोगा सस्पे...</td>\n",
       "      <td>उत्तर प्रदेश के बागपत में बिना अनुमति के बड़ी ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>928dcc9264915737630ab0e32f4a9b28</td>\n",
       "      <td>भोपाल: मध्य प्रदेश की पूर्व मुख्यमंत्री और बीज...</td>\n",
       "      <td>कृषि क़ानूनों की वापसी की घोषणा पर मैं अवाक रह...</td>\n",
       "      <td>उमा भारती ने कहा कि अगर तीन कृषि कानूनों की मह...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  a3d72cd62e7e1b5529dd254a85fa2b5a   \n",
       "1  f8904fd63c1d257dc5ee9b529df4a097   \n",
       "2  4e89ee2300613ae0c0e8db4ed0e2c7aa   \n",
       "3  9a382557dc6afda0dfaf04210d16224f   \n",
       "4  928dcc9264915737630ab0e32f4a9b28   \n",
       "\n",
       "                                             Article  \\\n",
       "0  भुवनेश्वर : भारत ने शनिवार को ओडिशा के बालासोर...   \n",
       "1  नई दिल्ली। देश में कोरोना की संभावित तीसरी लहर...   \n",
       "2  बीजेपी यूपी में जनवरी के दूसरे हफ्ते से ब्राह्...   \n",
       "3  बागपत: उत्तर प्रदेश के बागपत में बिना अनुमति क...   \n",
       "4  भोपाल: मध्य प्रदेश की पूर्व मुख्यमंत्री और बीज...   \n",
       "\n",
       "                                             Heading  \\\n",
       "0  भारत की बढ़ी ताकत, ‘अग्नि प्राइम’ मिसाइल का हु...   \n",
       "1  Covid-19 Vaccination: देश में कोविड टीके की 40...   \n",
       "2  यूपी में ब्राह्मण वोटरों को साधने की तैयारी कर...   \n",
       "3  बागपत में बिना इजाजत दाढ़ी रखने पर दरोगा सस्पे...   \n",
       "4  कृषि क़ानूनों की वापसी की घोषणा पर मैं अवाक रह...   \n",
       "\n",
       "                                             Summary  \n",
       "0  भारत ने शनिवार को ओडिशा के बालासोर तट पर ‘अग्न...  \n",
       "1  केंद्रीय स्वास्थ्य मंत्रालय के मुताबिक, आज शाम...  \n",
       "2  बीजेपी के केंद्र सरकार में ब्राह्मण मंत्रियों,...  \n",
       "3  उत्तर प्रदेश के बागपत में बिना अनुमति के बड़ी ...  \n",
       "4  उमा भारती ने कहा कि अगर तीन कृषि कानूनों की मह...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SAUMIL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a boy\n",
      "I am happy.\n",
      "मैं जानता हूँ\n",
      "मला ओळखलं पाहिजे\n"
     ]
    }
   ],
   "source": [
    "from transformers import MBartForConditionalGeneration, AutoModelForSeq2SeqLM\n",
    "from transformers import AlbertTokenizer, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicBART\", do_lower_case=False, use_fast=False, keep_accents=True)\n",
    "\n",
    "# Or use tokenizer = AlbertTokenizer.from_pretrained(\"ai4bharat/IndicBART\", do_lower_case=False, use_fast=False, keep_accents=True)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/IndicBART\")\n",
    "\n",
    "# Or use model = MBartForConditionalGeneration.from_pretrained(\"ai4bharat/IndicBART\")\n",
    "\n",
    "# Some initial mapping\n",
    "bos_id = tokenizer._convert_token_to_id_with_added_voc(\"<s>\")\n",
    "eos_id = tokenizer._convert_token_to_id_with_added_voc(\"</s>\")\n",
    "pad_id = tokenizer._convert_token_to_id_with_added_voc(\"<pad>\")\n",
    "# To get lang_id use any of ['<2as>', '<2bn>', '<2en>', '<2gu>', '<2hi>', '<2kn>', '<2ml>', '<2mr>', '<2or>', '<2pa>', '<2ta>', '<2te>']\n",
    "\n",
    "# First tokenize the input and outputs. The format below is how IndicBART was trained so the input should be \"Sentence </s> <2xx>\" where xx is the language code. Similarly, the output should be \"<2yy> Sentence </s>\". \n",
    "inp = tokenizer(\"I am a boy </s> <2en>\", add_special_tokens=False, return_tensors=\"pt\", padding=True).input_ids # tensor([[  466,  1981,    80, 25573, 64001, 64004]])\n",
    "\n",
    "out = tokenizer(\"<2hi> मैं  एक लड़का हूँ </s>\", add_special_tokens=False, return_tensors=\"pt\", padding=True).input_ids # tensor([[64006,   942,    43, 32720,  8384, 64001]])\n",
    "# Note that if you use any language other than Hindi or Marathi, you should convert its script to Devanagari using the Indic NLP Library.\n",
    "\n",
    "model_outputs=model(input_ids=inp, decoder_input_ids=out[:,0:-1], labels=out[:,1:])\n",
    "\n",
    "# For loss\n",
    "model_outputs.loss ## This is not label smoothed.\n",
    "\n",
    "# For logits\n",
    "model_outputs.logits\n",
    "\n",
    "# For generation. Pardon the messiness. Note the decoder_start_token_id.\n",
    "\n",
    "model.eval() # Set dropouts to zero\n",
    "\n",
    "model_output=model.generate(inp, use_cache=True, num_beams=4, max_length=20, min_length=1, early_stopping=True, pad_token_id=pad_id, bos_token_id=bos_id, eos_token_id=eos_id, decoder_start_token_id=tokenizer._convert_token_to_id_with_added_voc(\"<2en>\"))\n",
    "\n",
    "\n",
    "# Decode to get output strings\n",
    "\n",
    "decoded_output=tokenizer.decode(model_output[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "\n",
    "print(decoded_output) # I am a boy\n",
    "# Note that if your output language is not Hindi or Marathi, you should convert its script from Devanagari to the desired language using the Indic NLP Library.\n",
    "\n",
    "# What if we mask?\n",
    "\n",
    "inp = tokenizer(\"I am [MASK] </s> <2en>\", add_special_tokens=False, return_tensors=\"pt\", padding=True).input_ids\n",
    "\n",
    "model_output=model.generate(inp, use_cache=True, num_beams=4, max_length=20, min_length=1, early_stopping=True, pad_token_id=pad_id, bos_token_id=bos_id, eos_token_id=eos_id, decoder_start_token_id=tokenizer._convert_token_to_id_with_added_voc(\"<2en>\"))\n",
    "\n",
    "decoded_output=tokenizer.decode(model_output[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "\n",
    "print(decoded_output) # I am happy\n",
    "\n",
    "inp = tokenizer(\"मैं [MASK] हूँ </s> <2hi>\", add_special_tokens=False, return_tensors=\"pt\", padding=True).input_ids\n",
    "\n",
    "model_output=model.generate(inp, use_cache=True, num_beams=4, max_length=20, min_length=1, early_stopping=True, pad_token_id=pad_id, bos_token_id=bos_id, eos_token_id=eos_id, decoder_start_token_id=tokenizer._convert_token_to_id_with_added_voc(\"<2en>\"))\n",
    "\n",
    "decoded_output=tokenizer.decode(model_output[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "\n",
    "print(decoded_output) # मैं जानता हूँ\n",
    "\n",
    "inp = tokenizer(\"मला [MASK] पाहिजे </s> <2mr>\", add_special_tokens=False, return_tensors=\"pt\", padding=True).input_ids\n",
    "\n",
    "model_output=model.generate(inp, use_cache=True, num_beams=4, max_length=20, min_length=1, early_stopping=True, pad_token_id=pad_id, bos_token_id=bos_id, eos_token_id=eos_id, decoder_start_token_id=tokenizer._convert_token_to_id_with_added_voc(\"<2en>\"))\n",
    "\n",
    "decoded_output=tokenizer.decode(model_output[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "\n",
    "print(decoded_output) # मला ओळखलं पाहिजे\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
