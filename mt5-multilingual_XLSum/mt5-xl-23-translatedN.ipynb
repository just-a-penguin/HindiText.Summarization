{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:17:34.672793Z","iopub.status.busy":"2024-04-25T10:17:34.672435Z","iopub.status.idle":"2024-04-25T10:17:38.461532Z","shell.execute_reply":"2024-04-25T10:17:38.460438Z","shell.execute_reply.started":"2024-04-25T10:17:34.672752Z"},"trusted":true},"outputs":[],"source":["import csv\n","import pandas as pd \n","import torch\n","import torch.nn as nn\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:17:38.463968Z","iopub.status.busy":"2024-04-25T10:17:38.463517Z","iopub.status.idle":"2024-04-25T10:17:39.593240Z","shell.execute_reply":"2024-04-25T10:17:39.592223Z","shell.execute_reply.started":"2024-04-25T10:17:38.463940Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/nikita21546/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from datasets import load_dataset\n","\n","# s='train[:10]'\n","# dataset_train = load_dataset('csv', data_files='/kaggle/input/translated-data/Translated_hindi_train.csv')\n","# dataset_val = load_dataset('csv', data_files='/kaggle/input/summariser-data2022/val.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:17:39.594982Z","iopub.status.busy":"2024-04-25T10:17:39.594467Z","iopub.status.idle":"2024-04-25T10:17:39.599207Z","shell.execute_reply":"2024-04-25T10:17:39.598241Z","shell.execute_reply.started":"2024-04-25T10:17:39.594954Z"},"trusted":true},"outputs":[],"source":["# dataset_train"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:17:39.602631Z","iopub.status.busy":"2024-04-25T10:17:39.602226Z","iopub.status.idle":"2024-04-25T10:17:43.725166Z","shell.execute_reply":"2024-04-25T10:17:43.724333Z","shell.execute_reply.started":"2024-04-25T10:17:39.602590Z"},"trusted":true},"outputs":[],"source":["df_train = pd.read_csv('Translated_hindi_train.csv')     \n","# df_val = pd.read_csv('/kaggle/input/summariser-data2022/val.csv')     "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:17:43.727049Z","iopub.status.busy":"2024-04-25T10:17:43.726537Z","iopub.status.idle":"2024-04-25T10:17:43.734017Z","shell.execute_reply":"2024-04-25T10:17:43.732957Z","shell.execute_reply.started":"2024-04-25T10:17:43.727009Z"},"trusted":true},"outputs":[],"source":["article_limit = 300\n","# summary_limit=\n","def resize(article,summary):\n","    a=[]\n","    s=[]\n","    for i in range(len(article)):\n","        if(len(article[i].split())>article_limit):\n","            a.append(article[i])\n","            s.append(summary[i])\n","        else:\n","            continue\n","    \n","    return a,s\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:17:43.736426Z","iopub.status.busy":"2024-04-25T10:17:43.735547Z","iopub.status.idle":"2024-04-25T10:17:43.749183Z","shell.execute_reply":"2024-04-25T10:17:43.748193Z","shell.execute_reply.started":"2024-04-25T10:17:43.736389Z"},"trusted":true},"outputs":[],"source":["train_article = df_train['Article'].tolist()[:2000]\n","train_summary = df_train['Summary'].tolist()[:2000]\n","# train_article,train_summary = resize(train_article,train_summary)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:17:43.750754Z","iopub.status.busy":"2024-04-25T10:17:43.750397Z","iopub.status.idle":"2024-04-25T10:17:43.761524Z","shell.execute_reply":"2024-04-25T10:17:43.760566Z","shell.execute_reply.started":"2024-04-25T10:17:43.750727Z"},"trusted":true},"outputs":[{"data":{"text/plain":["2000"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["len(train_article)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:17:43.763326Z","iopub.status.busy":"2024-04-25T10:17:43.762991Z","iopub.status.idle":"2024-04-25T10:17:44.331473Z","shell.execute_reply":"2024-04-25T10:17:44.330353Z","shell.execute_reply.started":"2024-04-25T10:17:43.763289Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1800\n","DatasetDict({\n","    train: Dataset({\n","        features: ['Article', 'Summary'],\n","        num_rows: 1800\n","    })\n","})\n"]}],"source":["# from torch.utils.data import Dataset\n","from datasets import DatasetDict, Dataset\n","\n","x=100\n","\n","t=int(len(train_article)*0.9)\n","print(t)\n","\n","data_dict = {\n","    \"Article\": train_article[:t],\n","    \"Summary\": train_summary[:t]\n","}\n","\n","# Create a Dataset object from the dictionary\n","dataset_train = Dataset.from_dict(data_dict)\n","\n","dict_train = DatasetDict({\n","    'train': dataset_train,\n","    # Add more datasets for validation, test, etc., as needed\n","})\n","\n","print((dict_train))\n","# print(t)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:17:44.333074Z","iopub.status.busy":"2024-04-25T10:17:44.332722Z","iopub.status.idle":"2024-04-25T10:17:44.395971Z","shell.execute_reply":"2024-04-25T10:17:44.394951Z","shell.execute_reply.started":"2024-04-25T10:17:44.333047Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'datasets.dataset_dict.DatasetDict'>\n"]},{"data":{"text/plain":["DatasetDict({\n","    validation: Dataset({\n","        features: ['Article', 'Summary'],\n","        num_rows: 200\n","    })\n","})"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["\n","# val_article = df_val['Article'].tolist()[:x]\n","# val_summary = df_val['Summary'].tolist()[:x]\n","\n","val_article = train_article[t:]\n","val_summary = train_summary[t:] \n","\n","# val_article,val_summary = resize(val_article,val_summary)\n","\n","data_dict = {\n","    \"Article\": val_article,\n","    \"Summary\": val_summary\n","}\n","\n","# Create a Dataset object from the dictionary\n","dataset_val = Dataset.from_dict(data_dict)\n","\n","dict_val = DatasetDict({\n","    'validation': dataset_val,\n","    # Add more datasets for validation, test, etc., as needed\n","})\n","\n","print(type(dict_val))\n","dict_val"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:17:44.400902Z","iopub.status.busy":"2024-04-25T10:17:44.400582Z","iopub.status.idle":"2024-04-25T10:18:15.020801Z","shell.execute_reply":"2024-04-25T10:18:15.019797Z","shell.execute_reply.started":"2024-04-25T10:17:44.400877Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","/home/nikita21546/.local/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]},{"data":{"text/plain":["MT5ForConditionalGeneration(\n","  (shared): Embedding(250112, 768)\n","  (encoder): MT5Stack(\n","    (embed_tokens): Embedding(250112, 768)\n","    (block): ModuleList(\n","      (0): MT5Block(\n","        (layer): ModuleList(\n","          (0): MT5LayerSelfAttention(\n","            (SelfAttention): MT5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): MT5LayerFF(\n","            (DenseReluDense): MT5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x MT5Block(\n","        (layer): ModuleList(\n","          (0): MT5LayerSelfAttention(\n","            (SelfAttention): MT5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): MT5LayerFF(\n","            (DenseReluDense): MT5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): MT5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): MT5Stack(\n","    (embed_tokens): Embedding(250112, 768)\n","    (block): ModuleList(\n","      (0): MT5Block(\n","        (layer): ModuleList(\n","          (0): MT5LayerSelfAttention(\n","            (SelfAttention): MT5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): MT5LayerCrossAttention(\n","            (EncDecAttention): MT5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): MT5LayerFF(\n","            (DenseReluDense): MT5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x MT5Block(\n","        (layer): ModuleList(\n","          (0): MT5LayerSelfAttention(\n","            (SelfAttention): MT5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): MT5LayerCrossAttention(\n","            (EncDecAttention): MT5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): MT5LayerFF(\n","            (DenseReluDense): MT5DenseGatedActDense(\n","              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n","              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): MT5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): MT5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=250112, bias=False)\n",")"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Load model directly\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","# tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicBART\")\n","# model = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/IndicBART\")\n","# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","# tokenizer = AutoTokenizer.from_pretrained(\"Someman/bart-hindi\")\n","# model = AutoModelForSeq2SeqLM.from_pretrained(\"Someman/bart-hindi\")\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/mT5_multilingual_XLSum\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"csebuetnlp/mT5_multilingual_XLSum\")\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:18:15.022626Z","iopub.status.busy":"2024-04-25T10:18:15.022073Z","iopub.status.idle":"2024-04-25T10:18:15.028068Z","shell.execute_reply":"2024-04-25T10:18:15.026947Z","shell.execute_reply.started":"2024-04-25T10:18:15.022587Z"},"trusted":true},"outputs":[],"source":["# from transformers import AutoTokenizer\n","# import torch\n","\n","# df_test = pd.read_csv('/kaggle/input/summariser-data2022/test.csv')\n","# text= df_test['Article'].tolist()[12]\n","\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# model = model.to(device)\n","\n","# inputs = tokenizer(text, return_tensors=\"pt\")\n","\n","# # Move the input tensors to the same device as the model\n","# inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","# # Generate outputs using the model\n","# with torch.no_grad():\n","#     # Access the correct key for `input_ids` in the `inputs` dictionary\n","#     input_ids = inputs[\"input_ids\"]\n","#     outputs = model.generate(input_ids, max_new_tokens=70, do_sample=False)\n","\n","# generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","# print(\"Generated Text:\", generated_text)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:18:15.030000Z","iopub.status.busy":"2024-04-25T10:18:15.029577Z","iopub.status.idle":"2024-04-25T10:18:18.599672Z","shell.execute_reply":"2024-04-25T10:18:18.598566Z","shell.execute_reply.started":"2024-04-25T10:18:15.029963Z"},"trusted":true},"outputs":[],"source":["# summary = df_test['Summary'].tolist()[12]\n","# summary"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:18:18.602259Z","iopub.status.busy":"2024-04-25T10:18:18.601278Z","iopub.status.idle":"2024-04-25T10:18:18.608044Z","shell.execute_reply":"2024-04-25T10:18:18.606835Z","shell.execute_reply.started":"2024-04-25T10:18:18.602218Z"},"trusted":true},"outputs":[],"source":["# text"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:18:18.609740Z","iopub.status.busy":"2024-04-25T10:18:18.609372Z","iopub.status.idle":"2024-04-25T10:18:18.617177Z","shell.execute_reply":"2024-04-25T10:18:18.615969Z","shell.execute_reply.started":"2024-04-25T10:18:18.609712Z"},"trusted":true},"outputs":[],"source":["max_input_length = 600\n","max_target_length = 40\n","\n","prefix=\"summarize: \"\n","x=10\n","def preprocess_function(examples):\n","    inputs = [prefix + doc for doc in examples[\"Article\"]]\n","    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True,padding='max_length')\n","\n","    # Setup the tokenizer for targets\n","    labels = tokenizer(text_target=examples[\"Summary\"], max_length=max_target_length, truncation=True,padding='max_length')\n","#     labels = tokenizer(text_target=examples[\"Summary\"], padding='longest', truncation=True)\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:18:18.618673Z","iopub.status.busy":"2024-04-25T10:18:18.618357Z","iopub.status.idle":"2024-04-25T10:18:29.651444Z","shell.execute_reply":"2024-04-25T10:18:29.650312Z","shell.execute_reply.started":"2024-04-25T10:18:18.618648Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Map: 100%|██████████| 1800/1800 [00:00<00:00, 2213.23 examples/s]\n","Map: 100%|██████████| 200/200 [00:00<00:00, 2062.43 examples/s]\n"]}],"source":["# inp = preprocess_function(dataset_train['train'])\n","\n","# x=10\n","# tokenised_data_train = dataset_train.map(preprocess_function, batched=True)\n","# tokenised_data_val = dataset_val.map(preprocess_function, batched=True)\n","\n","tokenised_data_train = dict_train.map(preprocess_function, batched=True)\n","tokenised_data_val = dict_val.map(preprocess_function, batched=True)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:18:29.653028Z","iopub.status.busy":"2024-04-25T10:18:29.652698Z","iopub.status.idle":"2024-04-25T10:18:29.660037Z","shell.execute_reply":"2024-04-25T10:18:29.658939Z","shell.execute_reply.started":"2024-04-25T10:18:29.653000Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['Article', 'Summary', 'input_ids', 'attention_mask', 'labels'],\n","        num_rows: 1800\n","    })\n","})"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["(tokenised_data_train)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:18:29.661598Z","iopub.status.busy":"2024-04-25T10:18:29.661293Z","iopub.status.idle":"2024-04-25T10:18:30.976480Z","shell.execute_reply":"2024-04-25T10:18:30.975594Z","shell.execute_reply.started":"2024-04-25T10:18:29.661573Z"},"trusted":true},"outputs":[],"source":["import nltk\n","import numpy as np\n","\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    \n","    # Rouge expects a newline after each sentence\n","    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n","    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n","    \n","    # Note that other metrics may not have a `use_aggregator` parameter\n","    # and thus will return a list, computing a metric for each sentence.\n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n","    # Extract a few results\n","    result = {key: value * 100 for key, value in result.items()}\n","    \n","    # Add mean generated length\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    \n","    return {k: round(v, 4) for k, v in result.items()}"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:18:30.978184Z","iopub.status.busy":"2024-04-25T10:18:30.977830Z","iopub.status.idle":"2024-04-25T10:18:40.876378Z","shell.execute_reply":"2024-04-25T10:18:40.875472Z","shell.execute_reply.started":"2024-04-25T10:18:30.978148Z"},"trusted":true},"outputs":[],"source":["from transformers import DataCollatorForSeq2Seq\n","\n","data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model='mT5_multilingual_XLSum')"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:18:40.878269Z","iopub.status.busy":"2024-04-25T10:18:40.877956Z","iopub.status.idle":"2024-04-25T10:19:14.783996Z","shell.execute_reply":"2024-04-25T10:19:14.782690Z","shell.execute_reply.started":"2024-04-25T10:18:40.878244Z"},"trusted":true},"outputs":[],"source":["# !pip install rouge_score\n","# !pip install evaluate"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:19:14.786173Z","iopub.status.busy":"2024-04-25T10:19:14.785754Z","iopub.status.idle":"2024-04-25T10:19:15.466397Z","shell.execute_reply":"2024-04-25T10:19:15.465441Z","shell.execute_reply.started":"2024-04-25T10:19:14.786131Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","import evaluate\n","\n","# rouge = evaluate.load(\"rouge\")\n","\n","\n","batch_size = 1\n","# model_name = model_checkpoint.split(\"/\")[-1]\n","args = Seq2SeqTrainingArguments(\n","    output_dir=\"mT5_multilingual_XLSum\",\n","#     eval_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    weight_decay=0.01,\n","    save_total_limit=1,\n","    num_train_epochs=1,\n","    predict_with_generate=True,\n","    fp16=False,\n","    bf16=True,\n","    save_steps=500  ,\n",")\n","\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:19:15.467959Z","iopub.status.busy":"2024-04-25T10:19:15.467649Z","iopub.status.idle":"2024-04-25T10:19:15.472699Z","shell.execute_reply":"2024-04-25T10:19:15.471655Z","shell.execute_reply.started":"2024-04-25T10:19:15.467933Z"},"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:19:15.474474Z","iopub.status.busy":"2024-04-25T10:19:15.474116Z","iopub.status.idle":"2024-04-25T10:19:15.485967Z","shell.execute_reply":"2024-04-25T10:19:15.484949Z","shell.execute_reply.started":"2024-04-25T10:19:15.474447Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['Article', 'Summary', 'input_ids', 'attention_mask', 'labels'],\n","        num_rows: 1800\n","    })\n","})"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["tokenised_data_train\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T10:19:15.487629Z","iopub.status.busy":"2024-04-25T10:19:15.487319Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/nikita21546/.local/lib/python3.8/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1800' max='1800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1800/1800 04:52, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.261300</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.192800</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>2.021100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 84, 'num_beams': 4, 'length_penalty': 0.6, 'no_repeat_ngram_size': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 84, 'num_beams': 4, 'length_penalty': 0.6, 'no_repeat_ngram_size': 2}\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 84, 'num_beams': 4, 'length_penalty': 0.6, 'no_repeat_ngram_size': 2}\n"]},{"data":{"text/plain":["TrainOutput(global_step=1800, training_loss=2.104666002061632, metrics={'train_runtime': 293.6417, 'train_samples_per_second': 6.13, 'train_steps_per_second': 6.13, 'total_flos': 2529237934080000.0, 'train_loss': 2.104666002061632, 'epoch': 1.0})"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["trainer = Seq2SeqTrainer(\n","    model,\n","    args,\n","    train_dataset=tokenised_data_train[\"train\"],\n","    eval_dataset=tokenised_data_val[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    # compute_metrics=compute_metrics\n","#      data_collator=data_collator,\n",")\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":24,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["print()"]},{"cell_type":"code","execution_count":25,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["'summarise: सरकारी नौकरी की तलाश में जुटे युवाओं के लिए हम फिर से 5 लेटेस्ट नौकरियों की जानकारी के साथ हाजिर हैं। राजस्थान हाईकोर्ट में स्टेनोग्राफर के 277 पदों पर वैकेंसी है। आवेदन की शुरुआत एक अगस्त 2023 से होगी।\\nरेल इंडिया टेक्निकल एंड इकोनॉमिक सर्विस (राइट्स) ने भारत के रेल मंत्रालय के तहत ड्राफ्ट्समैन सिविल इंजीनियर, पर्यावरण सामाजिक निगरानी विशेषज्ञ, जूनियर डिजाइन इंजीनियर के 111 पदों के लिए ऑनलाइन आवेदन शुरू कर दिया है। 7 अगस्त तक ऑनलाइन आवेदन कर सकते हैं।\\nभुवनेश्वर एम्स में सीनियर नर्सिंग ऑफिसर, स्टोर कीपर, कैशियर, कनिष्ठ प्रशासनिक सहायक, मेडिकल रिकॉर्ड तकनीशियन (रिकॉर्ड क्लर्क), वायरमैन, फार्मासिस्ट के 775 पदों के लिए वैकेंसी थी। अगर आप अभी तक अप्लाई नहीं कर सके हैं तो आज यानी 30 जुलाई लास्ट डेट है।\\nभू यानी बनारस हिंदू विश्वविद्यालय ने असिस्टेंट प्रोफेसर, एसोसिएट प्रोफेसर और प्रोफेसर के 307 पदों पर भर्ती निकाली है। अप्लाई करने की लास्ट डेट कल यानी 31 जुलाई 2023 है।\\nनेत्र परीक्षण अधिकारी के 157 पदों पर भर्ती निकली है। आवेदन की आखिरी डेट 7 अगस्त 2023 है। सिलेक्शन होने पर 25,500 रुपए से 81,100 रुपए हर महीना सैलरी मिलेगी।\\nआइए, 5 नौकरियों की डिटेल्ड जानकारी आगे 5 ग्राफिक्स में जानते हैं। छठे ग्राफिक में करेंट अफेयर्स के 10 सवाल और उनके जवाब होंगे।\\nआपने यहां 5 नौकरियों के बारे में जाना। आपके मन में कुछ सवाल होंगे। इसलिए आप दिए गए वेबसाइट के जरिए ऑफिशियल नोटिफिकेशन को जरूर देखें। बाकी जिन नौकरियों के बारे में बताया गया है, अगर लगता है कि इससे आपके भाई-दोस्त या फिर रिश्तेदार की जरूरत पूरी होती है तो उन्हें यह खबर जरूर भेजें।\\nआखिर में हम 10 लेटेस्ट करेंट अफेयर्स के सवाल-जवाब दे रहे हैं। इन्हें रोज देखिए। हो सके तो सेव करते जाएं। ताकि आगामी परीक्षाओं में यह आपके लिए फायदेमंद साबित हों।'"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["text = df_train['Article'].tolist()[11]\n","text='summarise: '+text\n","text"]},{"cell_type":"code","execution_count":26,"metadata":{"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/working/tokenizer.pkl'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save tokenizer\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/tokenizer.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(tokenizer, f)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/tokenizer.pkl'"]}],"source":["# Save tokenizer\n","import pickle\n","with open('/kaggle/working/tokenizer.pkl', 'wb') as f:\n","    pickle.dump(tokenizer, f)"]},{"cell_type":"code","execution_count":52,"metadata":{"trusted":true},"outputs":[],"source":["import pickle\n","\n","# Save model\n","with open('mt5_xl_23_translated_modelN.pkl', 'wb') as f:\n","    pickle.dump(model, f)\n","\n","# Save tokenizer\n","with open('mt5_xl_23_translated_tokenizerN.pkl', 'wb') as f:\n","    pickle.dump(tokenizer, f)\n"]},{"cell_type":"code","execution_count":29,"metadata":{"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/summariser-data2022/test.csv'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df_test \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/summariser-data2022/test.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/summariser-data2022/test.csv'"]}],"source":["import pandas as pd\n","\n","df_test = pd.read_csv('/kaggle/input/summariser-data2022/test.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import pipeline\n","# prin\n","with open('/kaggle/working/Indic_Bart.pkl', 'rb') as f:\n","    model = pickle.load(f)\n","text= df_test['Article'].tolist()[12]\n","summarizer = pipeline(\"summarization\", model=model,tokenizer=AutoTokenizer.from_pretrained(\"/kaggle/working/tokeniser\"))\n","summarizer(text)"]},{"cell_type":"code","execution_count":30,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["'summarise: सरकारी नौकरी की तलाश में जुटे युवाओं के लिए हम फिर से 5 लेटेस्ट नौकरियों की जानकारी के साथ हाजिर हैं। राजस्थान हाईकोर्ट में स्टेनोग्राफर के 277 पदों पर वैकेंसी है। आवेदन की शुरुआत एक अगस्त 2023 से होगी।\\nरेल इंडिया टेक्निकल एंड इकोनॉमिक सर्विस (राइट्स) ने भारत के रेल मंत्रालय के तहत ड्राफ्ट्समैन सिविल इंजीनियर, पर्यावरण सामाजिक निगरानी विशेषज्ञ, जूनियर डिजाइन इंजीनियर के 111 पदों के लिए ऑनलाइन आवेदन शुरू कर दिया है। 7 अगस्त तक ऑनलाइन आवेदन कर सकते हैं।\\nभुवनेश्वर एम्स में सीनियर नर्सिंग ऑफिसर, स्टोर कीपर, कैशियर, कनिष्ठ प्रशासनिक सहायक, मेडिकल रिकॉर्ड तकनीशियन (रिकॉर्ड क्लर्क), वायरमैन, फार्मासिस्ट के 775 पदों के लिए वैकेंसी थी। अगर आप अभी तक अप्लाई नहीं कर सके हैं तो आज यानी 30 जुलाई लास्ट डेट है।\\nभू यानी बनारस हिंदू विश्वविद्यालय ने असिस्टेंट प्रोफेसर, एसोसिएट प्रोफेसर और प्रोफेसर के 307 पदों पर भर्ती निकाली है। अप्लाई करने की लास्ट डेट कल यानी 31 जुलाई 2023 है।\\nनेत्र परीक्षण अधिकारी के 157 पदों पर भर्ती निकली है। आवेदन की आखिरी डेट 7 अगस्त 2023 है। सिलेक्शन होने पर 25,500 रुपए से 81,100 रुपए हर महीना सैलरी मिलेगी।\\nआइए, 5 नौकरियों की डिटेल्ड जानकारी आगे 5 ग्राफिक्स में जानते हैं। छठे ग्राफिक में करेंट अफेयर्स के 10 सवाल और उनके जवाब होंगे।\\nआपने यहां 5 नौकरियों के बारे में जाना। आपके मन में कुछ सवाल होंगे। इसलिए आप दिए गए वेबसाइट के जरिए ऑफिशियल नोटिफिकेशन को जरूर देखें। बाकी जिन नौकरियों के बारे में बताया गया है, अगर लगता है कि इससे आपके भाई-दोस्त या फिर रिश्तेदार की जरूरत पूरी होती है तो उन्हें यह खबर जरूर भेजें।\\nआखिर में हम 10 लेटेस्ट करेंट अफेयर्स के सवाल-जवाब दे रहे हैं। इन्हें रोज देखिए। हो सके तो सेव करते जाएं। ताकि आगामी परीक्षाओं में यह आपके लिए फायदेमंद साबित हों।'"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["text"]},{"cell_type":"code","execution_count":31,"metadata":{"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'df_test' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t\u001b[38;5;241m=\u001b[39m\u001b[43mdf_test\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSummary\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m12\u001b[39m]\n\u001b[1;32m      2\u001b[0m t\n","\u001b[0;31mNameError\u001b[0m: name 'df_test' is not defined"]}],"source":["t=df_test['Summary'].tolist()[12]\n","t"]},{"cell_type":"code","execution_count":32,"metadata":{"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/working/Indic_Bart.pkl'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/Indic_Bart.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     model \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/working/tokeniser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/Indic_Bart.pkl'"]}],"source":["with open('/kaggle/working/Indic_Bart.pkl', 'rb') as f:\n","    model = pickle.load(f)\n","tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/working/tokeniser\")"]},{"cell_type":"code","execution_count":33,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Generated Text: राजस्थान हाईकोर्ट में स्टेनोग्राफर के 277 पदों पर वैकेंसी\n"]}],"source":["from transformers import AutoTokenizer\n","import torch\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","inputs = tokenizer(text, return_tensors=\"pt\")\n","\n","# Move the input tensors to the same device as the model\n","inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","# Generate outputs using the model\n","with torch.no_grad():\n","    # Access the correct key for `input_ids` in the `inputs` dictionary\n","    input_ids = inputs[\"input_ids\"]\n","    outputs = model.generate(input_ids, max_new_tokens=100, do_sample=False)\n","\n","generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","print(\"Generated Text:\", generated_text)\n"]},{"cell_type":"code","execution_count":34,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["'summarise: सरकारी नौकरी की तलाश में जुटे युवाओं के लिए हम फिर से 5 लेटेस्ट नौकरियों की जानकारी के साथ हाजिर हैं। राजस्थान हाईकोर्ट में स्टेनोग्राफर के 277 पदों पर वैकेंसी है। आवेदन की शुरुआत एक अगस्त 2023 से होगी।\\nरेल इंडिया टेक्निकल एंड इकोनॉमिक सर्विस (राइट्स) ने भारत के रेल मंत्रालय के तहत ड्राफ्ट्समैन सिविल इंजीनियर, पर्यावरण सामाजिक निगरानी विशेषज्ञ, जूनियर डिजाइन इंजीनियर के 111 पदों के लिए ऑनलाइन आवेदन शुरू कर दिया है। 7 अगस्त तक ऑनलाइन आवेदन कर सकते हैं।\\nभुवनेश्वर एम्स में सीनियर नर्सिंग ऑफिसर, स्टोर कीपर, कैशियर, कनिष्ठ प्रशासनिक सहायक, मेडिकल रिकॉर्ड तकनीशियन (रिकॉर्ड क्लर्क), वायरमैन, फार्मासिस्ट के 775 पदों के लिए वैकेंसी थी। अगर आप अभी तक अप्लाई नहीं कर सके हैं तो आज यानी 30 जुलाई लास्ट डेट है।\\nभू यानी बनारस हिंदू विश्वविद्यालय ने असिस्टेंट प्रोफेसर, एसोसिएट प्रोफेसर और प्रोफेसर के 307 पदों पर भर्ती निकाली है। अप्लाई करने की लास्ट डेट कल यानी 31 जुलाई 2023 है।\\nनेत्र परीक्षण अधिकारी के 157 पदों पर भर्ती निकली है। आवेदन की आखिरी डेट 7 अगस्त 2023 है। सिलेक्शन होने पर 25,500 रुपए से 81,100 रुपए हर महीना सैलरी मिलेगी।\\nआइए, 5 नौकरियों की डिटेल्ड जानकारी आगे 5 ग्राफिक्स में जानते हैं। छठे ग्राफिक में करेंट अफेयर्स के 10 सवाल और उनके जवाब होंगे।\\nआपने यहां 5 नौकरियों के बारे में जाना। आपके मन में कुछ सवाल होंगे। इसलिए आप दिए गए वेबसाइट के जरिए ऑफिशियल नोटिफिकेशन को जरूर देखें। बाकी जिन नौकरियों के बारे में बताया गया है, अगर लगता है कि इससे आपके भाई-दोस्त या फिर रिश्तेदार की जरूरत पूरी होती है तो उन्हें यह खबर जरूर भेजें।\\nआखिर में हम 10 लेटेस्ट करेंट अफेयर्स के सवाल-जवाब दे रहे हैं। इन्हें रोज देखिए। हो सके तो सेव करते जाएं। ताकि आगामी परीक्षाओं में यह आपके लिए फायदेमंद साबित हों।'"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["text"]},{"cell_type":"code","execution_count":35,"metadata":{"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'df_test' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t\u001b[38;5;241m=\u001b[39m\u001b[43mdf_test\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSummary\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m12\u001b[39m]\n\u001b[1;32m      2\u001b[0m t\n","\u001b[0;31mNameError\u001b[0m: name 'df_test' is not defined"]}],"source":["t=df_test['Summary'].tolist()[12]\n","t"]},{"cell_type":"code","execution_count":36,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["'summarise: सरकारी नौकरी की तलाश में जुटे युवाओं के लिए हम फिर से 5 लेटेस्ट नौकरियों की जानकारी के साथ हाजिर हैं। राजस्थान हाईकोर्ट में स्टेनोग्राफर के 277 पदों पर वैकेंसी है। आवेदन की शुरुआत एक अगस्त 2023 से होगी।\\nरेल इंडिया टेक्निकल एंड इकोनॉमिक सर्विस (राइट्स) ने भारत के रेल मंत्रालय के तहत ड्राफ्ट्समैन सिविल इंजीनियर, पर्यावरण सामाजिक निगरानी विशेषज्ञ, जूनियर डिजाइन इंजीनियर के 111 पदों के लिए ऑनलाइन आवेदन शुरू कर दिया है। 7 अगस्त तक ऑनलाइन आवेदन कर सकते हैं।\\nभुवनेश्वर एम्स में सीनियर नर्सिंग ऑफिसर, स्टोर कीपर, कैशियर, कनिष्ठ प्रशासनिक सहायक, मेडिकल रिकॉर्ड तकनीशियन (रिकॉर्ड क्लर्क), वायरमैन, फार्मासिस्ट के 775 पदों के लिए वैकेंसी थी। अगर आप अभी तक अप्लाई नहीं कर सके हैं तो आज यानी 30 जुलाई लास्ट डेट है।\\nभू यानी बनारस हिंदू विश्वविद्यालय ने असिस्टेंट प्रोफेसर, एसोसिएट प्रोफेसर और प्रोफेसर के 307 पदों पर भर्ती निकाली है। अप्लाई करने की लास्ट डेट कल यानी 31 जुलाई 2023 है।\\nनेत्र परीक्षण अधिकारी के 157 पदों पर भर्ती निकली है। आवेदन की आखिरी डेट 7 अगस्त 2023 है। सिलेक्शन होने पर 25,500 रुपए से 81,100 रुपए हर महीना सैलरी मिलेगी।\\nआइए, 5 नौकरियों की डिटेल्ड जानकारी आगे 5 ग्राफिक्स में जानते हैं। छठे ग्राफिक में करेंट अफेयर्स के 10 सवाल और उनके जवाब होंगे।\\nआपने यहां 5 नौकरियों के बारे में जाना। आपके मन में कुछ सवाल होंगे। इसलिए आप दिए गए वेबसाइट के जरिए ऑफिशियल नोटिफिकेशन को जरूर देखें। बाकी जिन नौकरियों के बारे में बताया गया है, अगर लगता है कि इससे आपके भाई-दोस्त या फिर रिश्तेदार की जरूरत पूरी होती है तो उन्हें यह खबर जरूर भेजें।\\nआखिर में हम 10 लेटेस्ट करेंट अफेयर्स के सवाल-जवाब दे रहे हैं। इन्हें रोज देखिए। हो सके तो सेव करते जाएं। ताकि आगामी परीक्षाओं में यह आपके लिए फायदेमंद साबित हों।'"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["text"]},{"cell_type":"code","execution_count":37,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/bin/pip:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n","  from pkg_resources import load_entry_point\n","Collecting indic-nlp-library\n","  Downloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n","\u001b[K     |████████████████████████████████| 40 kB 1.2 MB/s eta 0:00:01\n","\u001b[?25hCollecting sphinx-argparse\n","  Downloading sphinx_argparse-0.4.0-py3-none-any.whl (12 kB)\n","Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.7/dist-packages (from indic-nlp-library) (1.1.0)\n","Collecting morfessor\n","  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from indic-nlp-library) (1.3.3)\n","Requirement already satisfied: numpy in /home/nikita21546/.local/lib/python3.7/site-packages (from indic-nlp-library) (1.21.6)\n","Requirement already satisfied: sphinx>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx-argparse->indic-nlp-library) (5.3.0)\n","Requirement already satisfied: docutils<0.18 in /usr/local/lib/python3.7/dist-packages (from sphinx-rtd-theme->indic-nlp-library) (0.17.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /home/nikita21546/.local/lib/python3.7/site-packages (from pandas->indic-nlp-library) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->indic-nlp-library) (2022.6)\n","Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.2)\n","Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.2)\n","Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n","Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n","Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.1.5)\n","Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.3)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.1.2)\n","Requirement already satisfied: Pygments>=2.12 in /home/nikita21546/.local/lib/python3.7/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.17.2)\n","Requirement already satisfied: snowballstemmer>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n","Requirement already satisfied: babel>=2.9 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.11.0)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.7.12)\n","Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n","Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.28.1)\n","Requirement already satisfied: packaging>=21.0 in /home/nikita21546/.local/lib/python3.7/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (24.0)\n","Requirement already satisfied: importlib-metadata>=4.8; python_version < \"3.10\" in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (5.0.0)\n","Requirement already satisfied: six>=1.5 in /home/nikita21546/.local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->indic-nlp-library) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=3.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.1.1)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.1.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.8)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/nikita21546/.local/lib/python3.7/site-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2019.11.28)\n","Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata>=4.8; python_version < \"3.10\"->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8; python_version < \"3.10\"->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (4.4.0)\n","Installing collected packages: sphinx-argparse, morfessor, indic-nlp-library\n","Successfully installed indic-nlp-library-0.92 morfessor-2.0.6 sphinx-argparse-0.4.0\n"]}],"source":["!pip install indic-nlp-library\n"]},{"cell_type":"code","execution_count":38,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Generated Text: सरकारी नौकरी की तलाश में जुटे युवाओं के लिए हम फिर से 5 लेटेस्ट\n"]}],"source":["from transformers import AutoTokenizer\n","import torch\n","\n","# with open('/kaggle/working/Indic_Bart.pkl', 'rb') as f:\n","#     model = pickle.load(f)\n","# tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/working/tokeniser\")\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# def summarise(s):\n","\n","inputs = tokenizer(text, return_tensors=\"pt\")\n","\n","# Move the input tensors to the same device as the model\n","inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","# Generate outputs using the model\n","with torch.no_grad():\n","    # Access the correct key for `input_ids` in the `inputs` dictionary\n","    input_ids = inputs[\"input_ids\"]\n","    outputs = model.generate(input_ids, max_new_tokens=80, do_sample=False)\n","\n","generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","# return generated_text\n","print(\"Generated Text:\", generated_text)"]},{"cell_type":"code","execution_count":39,"metadata":{"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'df_test' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m summaries \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m ori_summary \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m s\u001b[38;5;241m=\u001b[39m\u001b[43mdf_test\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSummary\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      4\u001b[0m a \u001b[38;5;241m=\u001b[39m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArticle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(s))\n","\u001b[0;31mNameError\u001b[0m: name 'df_test' is not defined"]}],"source":["summaries = []\n","ori_summary = []\n","s=df_test['Summary'].tolist()\n","a = df_test['Article'].tolist()\n","print(len(s))\n","ori_summary.append(s[0])\n","print(a[0])\n","# summaries.append(summarise(a[0]))\n","# for i in range(len(s)):\n","#     ori_summary.append(s[i])\n","#     summaries.append(summarise(a[i]))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install rouge"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_train=pd.read_csv('Translated_hindi_train.csv')\n","\n","df_test2=df_train"]},{"cell_type":"code","execution_count":48,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-48-64a1bdbb80e9>:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_test2['predicted_summary'] = df_test2['Article'].apply(predict_summary)\n"]}],"source":["\n","def predict_summary(text):\n","    inputs = tokenizer(text, return_tensors='pt', max_length=600, truncation=True)\n","    inputs.to(\"cuda\")\n","    summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=40, early_stopping=True)\n","    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","    return summary\n","\n","df_test2['predicted_summary'] = df_test2['Article'].apply(predict_summary)"]},{"cell_type":"code","execution_count":51,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Rouge-1 : 0.3409268450872674\n","Rouge-2 : 0.23242517666452361\n","Rouge-L : 0.32349552488193495\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-51-aaea770f66c2>:9: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_test2['rouge'] = df_test2.apply(calculate_rouge, axis=1)\n","<ipython-input-51-aaea770f66c2>:10: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_test2['rouge-1'] = df_test2['rouge'].apply(lambda x: x['rouge-1']['f'])\n","<ipython-input-51-aaea770f66c2>:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_test2['rouge-2'] = df_test2['rouge'].apply(lambda x: x['rouge-2']['f'])\n","<ipython-input-51-aaea770f66c2>:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_test2['rouge-l'] = df_test2['rouge'].apply(lambda x: x['rouge-l']['f'])\n"]}],"source":["from rouge import Rouge\n","\n","rouge = Rouge()\n","\n","\n","def calculate_rouge(row):\n","    return rouge.get_scores(row['predicted_summary'], row['Summary'], avg=True)\n","\n","df_test2['rouge'] = df_test2.apply(calculate_rouge, axis=1)\n","df_test2['rouge-1'] = df_test2['rouge'].apply(lambda x: x['rouge-1']['f'])\n","df_test2['rouge-2'] = df_test2['rouge'].apply(lambda x: x['rouge-2']['f'])\n","df_test2['rouge-l'] = df_test2['rouge'].apply(lambda x: x['rouge-l']['f'])\n","\n","print(\"Rouge-1 :\",df_test2['rouge-1'].mean())\n","print(\"Rouge-2 :\",df_test2['rouge-2'].mean())\n","print(\"Rouge-L :\",df_test2['rouge-l'].mean())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install rouge"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# # Define compute_metrics function\n","# def compute_metrics(eval_pred):\n","#     predictions, labels = eval_pred\n","#     decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","#     labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","#     decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","#     # Load ROUGE and BERT score metrics\n","#     rouge = load_metric('rouge')\n","#     bert_score = load_metric('bertscore')\n","\n","#     # Compute ROUGE and BERT scores\n","#     rouge_output = rouge.compute(predictions=decoded_preds, references=decoded_labels, rouge_types=[\"rougeL\", \"rouge2\"])\n","#     bert_score_output = bert_score.compute(predictions=decoded_preds, references=decoded_labels, lang=\"hi\")\n","\n","#     return {\n","#         \"rouge2\": rouge_output['rouge2'].mid.fmeasure,\n","#         \"rougeL\": rouge_output['rougeL'].mid.fmeasure,\n","#         \"bert_score\": bert_score_output['f1'][0]\n","#     }"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4845936,"sourceId":8184236,"sourceType":"datasetVersion"},{"datasetId":4861189,"sourceId":8204708,"sourceType":"datasetVersion"},{"datasetId":4869275,"sourceId":8215303,"sourceType":"datasetVersion"},{"datasetId":4873549,"sourceId":8220751,"sourceType":"datasetVersion"},{"datasetId":4873602,"sourceId":8220822,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
